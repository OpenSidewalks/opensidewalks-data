import json
import sys

import crossify.intersections
import crossify.crossings
import geopandas as gpd
import pandas as pd
import networkx as nx
import numpy as np
import rasterio as rio
import scipy
import sidewalkify
from shapely.geometry import mapping, shape
from shapely.geometry import Point, LinearRing, LineString, MultiPoint, Polygon

sys.path.append('../../src')
import data_helpers as dh


rule all:
    input:
        "output/transportation.geojson"


# TODO: these come from OSM - include in Snakefile.fetch
rule read_elevator_paths:
    input:
        'input/seattle_elevator_paths.geojson'
    output:
        'interim/raw/elevator_paths.geojson'
    shell: 'cp {input} {output}'


rule clean_elevator_paths:
    input:
        'interim/raw/elevator_paths.geojson'
    output:
        'interim/clean/elevator_paths.geojson'
    run:
        df = gpd.read_file('./input/seattle_elevator_paths.geojson')

        # Drop paths that have issues and/or are incomplete
        df = df[df['keep'] == 1]

        # Decide whether path is indoor (through building) or outdoor
        df['indoor'] = (df['highway'] == 'corridor').astype(int)

        # Add a 'layer' column set to 0 for downstream processing
        df['layer'] = 0

        # Rename and keep key columns
        df = df.rename(columns={'opening_ho': 'opening_hours', 'bld_name': 'via'})
        df = df[['geometry', 'indoor', 'layer', 'opening_hours', 'via']]
        df = gpd.GeoDataFrame(df)

        dh.io.gdf_to_geojson(df, output[0])


rule clean_streets:
    input:
        ['sourcedata/streets.geojson',
         'sourcedata/street_network_database.geojson']
    output:
        'interim/clean/streets.geojson'
    run:
        df = gpd.read_file(input[0])
        snd = gpd.read_file(input[1])

        # Rename columns to more standardized/semantic names
        rename = {
            'COMPKEY': 'pkey',
            'STNAME_ORD': 'name',
            'XSTRLO': 'street_low',
            'XSTRHI': 'street_high'
        }
        df = df.rename(columns=rename)

        # Categorize levels (elevated, at-grade, below-grade). Note: the
        # Seattle Street Network Database (SND) contained this information
        # directly, but is messy + large + only available as a shapefile. This
        # strategy, based on street naming conventions, was developed by
        # comparing street names in this dataset to the SND STRUCTURE_TYPE.

        # Bridges
        is_br = df.name.str.contains(' BR ') | df.name.str.endswith(' BR')
        # Viaducts
        is_vi = df.name.str.contains(' VI ') | df.name.str.endswith(' VI')
        # On ramps / off ramps
        is_onrp = df.name.str.contains(' ON RP ') | df.name.str.endswith(' ON RP')
        is_offrp = df.name.str.contains(' OFF RP ') | df.name.str.endswith(' OFF RP')
        is_rp = df.name.str.contains(' RP ') | df.name.str.endswith(' RP')

        elevated = df[is_br | is_vi | is_onrp | is_offrp | is_rp]

        # Tunnels
        below_grade = df[df.name.str.contains('TUNNEL')]

        df['layer'] = 0
        df.loc[elevated.index, 'layer'] = 1
        df.loc[below_grade.index, 'layer'] = -1

        # SND elevation info
        below = snd.loc[snd.STRUCTURE_TYPE == 0, 'COMPKEY']
        above = snd.loc[snd.STRUCTURE_TYPE == 2, 'COMPKEY']
        df.loc[df.pkey.isin(below), 'layer'] = -1
        df.loc[df.pkey.isin(above), 'layer'] = 1

        # Drop stairs, alleys, walkways, trails
        codemap = {
            'highway': 3,
            'alley': 5,
            'stairs': 6,
            'walkways': 7,
            'trails': 8
        }
        df = df[~df.pkey.isin(snd.loc[snd.SEGMENT_TYPE.isin(codemap.values()), 'COMPKEY'])]

        # Drop trails
        df = df[~(df.name.str.contains(' TRL ') | df.name.str.endswith(' TRL'))]

        # Drop alleys
        df = df[~(df.STREETTYPE == 'Alley')]
        df = df.drop(columns=['STREETTYPE'])

        # Drop the 'OBJECTID' column - it's pointless
        df = df.drop('OBJECTID', axis=1)

        dh.io.gdf_to_geojson(df, output[0])

rule clean_sidewalks:
    input:
        'sourcedata/sidewalks.geojson'
    output:
        'interim/clean/sidewalks.geojson'
    run:
        df = gpd.read_file(input[0])

        # Rename columns to more standardized/semantic names
        rename = {
            'COMPKEY': 'pkey',
            'SEGKEY': 'streets_pkey',
            'SW_WIDTH': 'width',
            'WIDTH': 'offset',
            'SURFTYPE': 'surface',
            'SIDE': 'side'
        }
        df = df.rename(columns=rename)

        # Unit conversions
        df['width'] = round(df['width'] * 0.0254, 2)  # inches to meters
        df['offset'] = df['offset'] * 0.3048 # feet to meters

        # Map surface values from SDOT keys to OSM keys
        df['surface2'] = None
        surface_map = {
            'AC': 'asphalt',
            'AC/AC': 'asphalt',
            'AC/PCC': 'asphalt',
            'BR': 'paving_stones',
            'GR': 'gravel',
            'PCC': 'concrete',
            'PCC-PAD': 'concrete',
            'PVAS': 'asphalt',
            'PVCC': 'concrete',
            'ST': 'asphalt',
            'UIMPRV': 'unimproved'
        }
        for key, value in surface_map.items():
            df.loc[(df[df['surface'] == key]).index, 'surface2'] = value

        # Rename temporary surface column back to primary
        df = df.drop('surface', axis=1)
        df = df.rename(columns={'surface2': 'surface'})

        # NOTE: SDOT marks sidewalks that don't even exist as 'unimproved'
        # surfaces. Drop these.
        df = df.drop(df[df['surface'] == 'unimproved'].index)

        # Drop the 'OBJECTID' column - it's pointless
        df = df.drop('OBJECTID', axis=1)

        # Drop offsets that make no sense and/or are undocumented
        df = df[df['offset'].abs() > 1e-2]

        # TODO: look into 0-width sidewalks. Some just don't exist, others do

        # Drop multiple-entry sidewalks.
        # FIXME: we need to account for these eventually, but right now it's
        # only sidewalks for 9 streets that have multiple entries. The reason
        # there are multiple sidewalks (more than 2) per street is due to
        # SDOT hacks for linear referencing to the street network.
        by_street_pkey = df.groupby('streets_pkey').count()['geometry']
        multiple = df[df['streets_pkey'].isin(by_street_pkey[by_street_pkey > 2].index)]
        for key, grp in multiple.groupby(['streets_pkey', 'side']):
            if grp.shape[0] > 1:
                # More than one sidewalk on this side! Keep only the first entry
                df = df.drop(grp.iloc[1:].index)

        # Drop unused columns
        df = df[['geometry'] + list(rename.values())]

        # Write to file
        dh.io.gdf_to_geojson(df, output[0])

rule clean_curbramps:
    input:
        'sourcedata/curbramps.geojson'
    output:
        'interim/clean/curbramps.geojson'
    run:
        df = gpd.read_file(input[0])

        df = df.loc[~df['SW_COMPKEY'].isnull()]

        df = df.rename(columns={'SW_COMPKEY': 'sw_pkey'})

        # Remove invalid geometries
        df = df[df.geometry.notna()]

        dh.io.gdf_to_geojson(df, output[0])


rule clean_crosswalks:
    input:
        'sourcedata/crosswalks.geojson'
    output:
        'interim/clean/crosswalks.geojson'
    run:
        df = gpd.read_file(input[0])

        # Rename columns
        df = df.rename(columns={
            'MIDBLOCK_CROSSWALK': 'midblock',
            'SEGKEY': 'st_pkey',
        })

        # Remove invalid geometries
        df = df[df.geometry.notna()]

        dh.io.gdf_to_geojson(df, output[0])

rule override_streets:
    input:
        ['interim/clean/streets.geojson',
         'input/override_streets.json']
    output:
        'interim/overridden/streets.geojson'
    run:
        df = gpd.read_file(input[0])

        # Specific overrides due to errors in the SDOT dataset
        with open(input[1]) as f:
            overrides = json.load(f)
            if 'layer' in overrides:
                for layer, pkeys in overrides['layer'].items():
                    df.loc[pkeys, 'layer'] = int(layer)

        dh.io.gdf_to_geojson(df, output[0])

rule override_sidewalks:
    input:
        ['interim/clean/sidewalks.geojson',
         'input/override_sidewalks.json']
    output:
        'interim/overridden/sidewalks.geojson'
    run:
        df = gpd.read_file(input[0])

        # Drop flagged 'bad data' sidewalks
        with open(input[1]) as f:
            override = json.load(f)

        to_remove = override['remove']
        df = df.loc[~df['pkey'].isin(to_remove)]

        to_add = override['add']
        entries = []
        for i, entry in enumerate(to_add):
            id = -(i + 1)
            entry['pkey'] = id
            entry['geometry'] = shape(entry['geometry'])
            entries.append(entry)
        df = pd.concat([df, gpd.GeoDataFrame(entries)])

        dh.io.gdf_to_geojson(df, output[0])

rule join:
    input:
        ['interim/overridden/sidewalks.geojson',
         'interim/overridden/streets.geojson']
    output:
        'interim/joined/sidewalks.geojson'
    run:
        sw = gpd.read_file(input[0])
        st = gpd.read_file(input[1])

        # Drop sidewalks that refer to non-existing streets (according to our
        # dataset)
        sw = sw[sw.streets_pkey.isin(st.pkey)]

        # Add street name to sidewalks
        sw['street_name'] = list(st.set_index('pkey').loc[sw.streets_pkey, 'name'])

        dh.io.gdf_to_geojson(sw, output[0])

rule draw_sidewalks:
    input:
        ['interim/joined/sidewalks.geojson',
         'interim/overridden/streets.geojson']
    output:
        ['interim/redrawn/sidewalks.geojson',
         'interim/redrawn/streets.geojson']
    run:
        sw = gpd.read_file(input[0])
        st = gpd.read_file(input[1])

        # Prepare for sidewalkify: rows = streets, sw_left + sw_right = offsets
        left = sw[sw.offset > 0].loc[:, ['geometry', 'offset', 'pkey', 'streets_pkey']]
        right = sw[sw.offset < 0].loc[:, ['geometry', 'offset', 'pkey', 'streets_pkey']]
        right.offset = right.offset.abs()

        st_pkey = st.set_index('pkey')
        left_st = left.set_index('streets_pkey')
        right_st = right.set_index('streets_pkey')

        st_pkey['sw_left'] = np.nan
        st_pkey.loc[left_st.index, 'sw_left'] = left_st.offset
        st_pkey.loc[left_st.index, 'pkey_left'] = left_st.pkey

        st_pkey.loc[right_st.index, 'sw_right'] = right_st.offset
        st_pkey.loc[right_st.index, 'pkey_right'] = right_st.pkey

        st = st_pkey

        # Restrict to udistrict temporarily (for testing purposes only)
        # bbox = [-122.3228, 47.6500, -122.3049, 47.6635]
        # idx = [q.object for q in st.sindex.intersection(bbox, objects=True)]
        # st = st.loc[idx]

        # Reproject into UTM
        st = dh.utm.gdf_to_utm(st)
        crs = st.crs

        # Draw sidewalks
        st['id'] = st.index
        paths = sidewalkify.graph.graph_workflow(st)
        redrawn = sidewalkify.draw.draw_sidewalks(paths)


        rows = []
        for i, path in enumerate(paths):
            n = i
            geom = LineString([node for node in path['nodes']])
            rows.append({
                'n': n,
                'cyclic': path['cyclic'],
                'geometry': geom
            })
        df_paths = gpd.GeoDataFrame(rows)
        df_paths.crs = crs
        df_paths = df_paths.to_crs({'init': 'epsg:4326'})

        dh.io.gdf_to_geojson(df_paths, 'test_paths.geojson')

        # Reproject to WGS84
        redrawn.crs = crs
        redrawn = redrawn.to_crs({'init': 'epsg:4326'})

        # Update redrawn with geometries (so that other metadata remains)
        # Note: 'forward' = 1 from sidewalkify means sidewalk was drawn on the
        # 'right' side of the street, 'forward' = 0 mean left. The 'street_id'
        # from sidewalkify corresponds to the input 'id' field, i.e. pkey

        # There are some redrawn that are missing from the final dataset, for
        # whatever reason (e.g., they got trimmed down to nothing during final
        # cleaning step).
        sw = sw[sw.streets_pkey.isin(redrawn.street_id)]
        sw.loc[sw.offset < 0, 'forward'] = 0
        sw.loc[sw.offset >= 0, 'forward'] = 1

        # Update initial sw dataset with redrawn sidewalk lines
        def update(row):
            street_match = redrawn.street_id == row.streets_pkey
            side_match = row.forward == redrawn.forward
            both = street_match & side_match
            indices = redrawn.index[both].tolist()
            if indices:
                sw.at[row.name, 'geometry'] = redrawn.loc[indices[0], 'geometry']
            else:
                sw.at[row.name, 'geometry'] = None

        sw.apply(update, axis=1)

        sw = sw.loc[~sw.geometry.isnull()]

        # Keep layer data
        sw['layer'] = list(st.loc[sw.streets_pkey, 'layer'])

        sw = sw.drop(columns=['offset'])

        dh.io.gdf_to_geojson(sw, output[0])

        st.crs = crs
        st = st.to_crs({'init': 'epsg:4326'})
        dh.io.gdf_to_geojson(st, output[1])


rule adjust_curbramps:
    input:
        ['interim/clean/curbramps.geojson',
         'interim/redrawn/sidewalks.geojson']
    output:
        'interim/redrawn/curbramps.geojson'
    run:
        df = gpd.read_file(input[0])
        sw = gpd.read_file(input[1])

        # Assign curbramps to sidewalk line start/mid/end
        def identify_position(cr_row):
            loc = cr_row['SW_LOCATION']
            if loc == 'M':
                return 'mid'

            sw_pkey = cr_row['sw_pkey']
            sidewalk = sw.loc[sw.pkey == sw_pkey]

            if sidewalk.shape[0]:
                sidewalk = sidewalk.iloc[0]
            else:
                return 'none'

            if sidewalk['forward']:
                # Sidewalk is in low address -> high address direction, keep
                # values
                if loc == 'H':
                    return 'end'
                else:
                    return 'start'
            else:
                # Sidewalk is in high address -> low address direction, swap
                if loc == 'H':
                    return 'start'
                else:
                    return 'end'

        # Adjust curb ramp positions
        def adjust(cr_row):
            sw_pkey = cr_row['sw_pkey']
            sidewalk = sw.loc[sw.pkey == sw_pkey].iloc[0]

            if cr_row['position'] == 'start':
                return Point(sidewalk.geometry.coords[0])
            elif cr_row['position'] == 'end':
                return Point(sidewalk.geometry.coords[-1])
            else:
                return sidewalk.geometry.interpolate(0.5, normalized=True)

        df = df.loc[df['sw_pkey'].isin(sw['pkey'])]
        df['position'] = df.apply(identify_position, axis=1)
        df = df.loc[df['position'] != 'none']
        df['geometry'] = df.apply(adjust, axis=1)

        dh.io.gdf_to_geojson(df, output[0])


rule draw_crossings:
    input:
        ['interim/redrawn/sidewalks.geojson',
         'interim/redrawn/streets.geojson']
    output:
        'interim/redrawn/crossings.geojson'
    run:
        sw = gpd.read_file(input[0])
        st = gpd.read_file(input[1])

        sw.pkey = sw.pkey.astype(float)
        st.pkey_left = st.pkey_left.astype(float)
        st.pkey_right = st.pkey_right.astype(float)

        # Restrict to udistrict temporarily (for testing purposes only)
        # bbox = [-122.3228, 47.6500, -122.3049, 47.6635]
        # idx = [q.object for q in st.sindex.intersection(bbox, objects=True)]
        # st = st.loc[idx]

        # Set sidewalk IDs to None if they're not in the sw dataset
        st.loc[~st.pkey_left.isin(sw.pkey), 'pkey_left'] = np.nan
        st.loc[~st.pkey_right.isin(sw.pkey), 'pkey_right'] = np.nan

        # FIXME: This is for dropping one street per boulevard, but that is not
        # a working strategy for handling crossings. Revisit!
        # for key, grp in st.groupby(['name', 'street_high', 'street_low']):
        #     if grp.shape[0] > 1:
        #         # Keep the first only
        #         st = st.drop(grp.iloc[1:].index)

        # Reproject into UTM
        sw = dh.utm.gdf_to_utm(sw)
        st = dh.utm.gdf_to_utm(st)

        keep = ['id', 'pkey_left', 'pkey_right']
        swap = [['pkey_left', 'pkey_right']]
        G = dh.circular_ordered_graph.circular_ordered_graph(st, 2, keep, swap)

        # FIXME: Treat streets with very similar azimuths and no 'in-between'
        # sidewalks as a single edge for crossings

        def extract_corner(sw_pkey, keep_index):
            if np.isnan(sw_pkey):
                return None
            matches = sw.loc[sw.pkey == sw_pkey, 'geometry']
            if matches.shape[0]:
                geometry = matches.iloc[0]
                return Point(geometry.coords[keep_index])
            return None


        # Use graph data to add crossings per-street
        T_range = [160, 200]
        rows = []
        for u, v, k, d in G.edges(data=True, keys=True):
            if G.degree(u) < 5:
                # Skip dead ends and continuing streets
                continue

            edges = G.nodes[u]['sorted_edges']
            n = len(edges)
            idx = edges.index((v, k))

            # Find left and right streets
            ccw_v, ccw_j = edges[idx - 1]
            cw_v, cw_j = edges[(idx + 1) % n]
            ccw = G[u][ccw_v][ccw_j]
            cw = G[u][cw_v][cw_j]

            corner_ccw = extract_corner(d['pkey_left'], 0)
            if corner_ccw is None:
                corner_ccw = extract_corner(ccw['pkey_right'], -1)
            if corner_ccw is None:
                # There's no corner on the counter-clockwise side at all
                continue

            corner_cw = extract_corner(d['pkey_right'], -1)
            if corner_cw is None:
                corner_cw = extract_corner(cw['pkey_left'], 0)
            if corner_cw is None:
                # There's no corner on the counter-clockwise side at all
                continue

            # Check for 'T' intersections, 'straighten' crossings at them
            dccw = (d['azimuth'] - ccw['azimuth']) % 360
            dcw = (d['azimuth'] - cw['azimuth']) % 360

            if (dccw > T_range[0]) and (dccw < T_range[1]):
                # They're basically parallel - it's a T intersection ending on
                # the left. Adjust the 'left' corner to be whatever point on
                # the left sidewalk is closest to the 'right' corner.
                matches = sw.loc[sw.pkey == d['pkey_left'], 'geometry']
                if matches.shape[0]:
                    geom = matches.iloc[0]
                    corner_ccw = geom.interpolate(geom.project(corner_cw))

            if (dcw > T_range[0]) and (dcw < T_range[1]):
                # They're basically parallel - it's a T intersection ending on
                # the right. Adjust the 'right' corner to be whatever point on
                # the right sidewalk is closest to the 'left' corner.
                matches = sw.loc[sw.pkey == d['pkey_right'], 'geometry']
                if matches.shape[0]:
                    geom = matches.iloc[0]
                    corner_cw = geom.interpolate(geom.project(corner_ccw))

            # The crossing is just connected corners. This is the step
            # where some constraints can be added.
            crossing_geom = LineString([corner_ccw, corner_cw])
            rows.append({
                'geometry': crossing_geom,
                'st_pkey': d['id'],
                'sw_left': d['pkey_left'],
                'sw_right': d['pkey_right'],
                'ccw_sw_right': ccw['pkey_right'],
                'cw_sw_left': cw['pkey_left'],
            })

        crossings = gpd.GeoDataFrame(rows)

        crossings.crs = st.crs
        crossings = crossings.to_crs({'init': 'epsg:4326'})
        dh.io.gdf_to_geojson(crossings, output[0])


rule annotate_crossings_with_crosswalks:
    input:
        ['interim/redrawn/crossings.geojson',
         'interim/clean/crosswalks.geojson']
    output:
        'interim/annotated/crossings_crosswalks.geojson'
    run:
        df = gpd.read_file(input[0])
        cw = gpd.read_file(input[1])

        # Reproject into UTM
        df = dh.utm.gdf_to_utm(df)
        cw = dh.utm.gdf_to_utm(cw)

        # Mark as having crosswalks if one is nearby
        def marked_within_dist(row, dist=3.5, default=None):
            g = row.geometry
            q = [q.object for q in cw.sindex.nearest(g.bounds, 1, objects=True)]
            in_bbox = cw.loc[q, 'geometry']
            if in_bbox.empty:
                return default
            else:
                return (in_bbox.distance(g) < dist).any()

        df['marked'] = df.apply(marked_within_dist, axis=1)

        # Reproject to WGS84
        df = df.to_crs({'init': 'epsg:4326'})

        dh.io.gdf_to_geojson(df, output[0])


rule annotate_crossings_with_curbramps:
    input:
        ['interim/annotated/crossings_crosswalks.geojson',
         'interim/redrawn/curbramps.geojson']
    output:
        'interim/annotated/crossings_curbramps.geojson'
    run:
        df = gpd.read_file(input[0])
        cr = gpd.read_file(input[1])
        df['curbramps_ccw'] = 0
        df['curbramps_cw'] = 0
        df['curbramps'] = 0

        starts = cr.loc[cr['position'] == 'start']
        ends = cr.loc[cr['position'] == 'end']

        left = df['sw_left'].isin(starts['sw_pkey'])
        ccw_right = df['ccw_sw_right'].isin(ends['sw_pkey'])
        df.loc[(left | ccw_right), 'curbramps_ccw'] = 1

        right = df['sw_right'].isin(starts['sw_pkey'])
        cw_left = df['cw_sw_left'].isin(starts['sw_pkey'])
        df.loc[(right | cw_left), 'curbramps_cw'] = 1

        both = (df['curbramps_ccw'] == 1) & (df['curbramps_cw'] == 1)

        df.loc[both, 'curbramps'] = 1

        df = df.drop(columns=['curbramps_ccw', 'curbramps_cw'])

        dh.io.gdf_to_geojson(df, output[0])


rule add_midblock_crosswalks:
    input:
        ['interim/clean/crosswalks.geojson',
         'interim/redrawn/curbramps.geojson',
         'interim/redrawn/sidewalks.geojson',
         'interim/redrawn/streets.geojson']
    output:
        'interim/annotated/crossings_mid.geojson'
    run:
        # TODO: Implement overrides for the 'midblock' key for some crossings.
        # They're marked as 'N' for being mid-block, but obviously are. See:
        # U-district

        # If there's a mid-block marked crosswalk and two mid-block curb ramps
        # associated with each sidewalk, draw a marked crossing w/ curb ramps
        # on each side
        cw = gpd.read_file(input[0])
        cr = gpd.read_file(input[1])
        sw = gpd.read_file(input[2])
        st = gpd.read_file(input[3])

        cw = dh.utm.gdf_to_utm(cw)
        cr = dh.utm.gdf_to_utm(cr)
        sw = dh.utm.gdf_to_utm(sw)
        st = dh.utm.gdf_to_utm(st)

        # Sanitize data for comparisons
        st = st.loc[~st['pkey_left'].isnull()]
        st = st.loc[~st['pkey_right'].isnull()]

        # Find mid-block crosswalks and curb ramps
        cw_mid = cw.loc[cw['midblock'] == 'Y']
        cr_mid = cr.loc[cr['position'] == 'mid']

        # Remove street keys not present in the streets dataset
        cw_mid = cw_mid.loc[cw_mid['st_pkey'].isin(st['id'])]


        rows = []
        for idx, row in cw_mid.iterrows():
            geom = row.geometry
            st_row = st.loc[st['id'] == row['st_pkey']].iloc[0]

            sw_left = sw.loc[sw['pkey'] == st_row['pkey_left']]
            if not sw_left.shape[0]:
                continue
            sw_left = sw_left.iloc[0]

            sw_right = sw.loc[sw['pkey'] == st_row['pkey_right']]
            if not sw_right.shape[0]:
                continue
            sw_right = sw_right.iloc[0]

            geom_left = sw_left['geometry']
            geom_right = sw_right['geometry']

            left = geom_left.interpolate(geom_left.project(geom))
            right = geom_right.interpolate(geom_right.project(geom))
            crossing_geom = LineString([left, right])

            cr_left = (cr_mid['sw_pkey'] == sw_left['pkey']).sum()
            cr_right = (cr_mid['sw_pkey'] == sw_left['pkey']).sum()
            if cr_left and cr_right:
                curbramps = True
            else:
                curbramps = False

            new = {}
            new['geometry'] = crossing_geom
            new['marked'] = 1
            new['curbramps'] = curbramps
            new['st_pkey'] = st_row['id']
            new['pkey'] = row['OBJECTID']

            rows.append(new)

        mid_crossings = gpd.GeoDataFrame(rows)

        mid_crossings.crs = cr.crs
        mid_crossings = mid_crossings.to_crs({'init': 'epsg:4326'})

        dh.io.gdf_to_geojson(mid_crossings, output[0])


rule join_crossings:
    input:
        ['interim/annotated/crossings_curbramps.geojson',
         'interim/annotated/crossings_mid.geojson',
         'interim/overridden/streets.geojson']
    output:
        'interim/annotated/crossings.geojson'
    run:
        main = gpd.read_file(input[0])
        mid = gpd.read_file(input[1])
        st = gpd.read_file(input[2])

        keep = ['geometry', 'curbramps', 'marked', 'st_pkey']
        main = main[keep]
        mid = mid[keep]

        combined = pd.concat([main, mid])

        # Look up the actual street name as well
        st_unique = st.drop_duplicates('pkey').set_index('pkey')

        combined['street_name'] = st_unique.loc[combined['st_pkey']]['name'].tolist()

        dh.io.gdf_to_geojson(combined, output[0])


rule intersection_elevations:
    input:
        ['sourcedata/dem.tif',
         'interim/overridden/streets.geojson']
    output:
        'interim/dem/intersection_elevations.geojson'
    run:
        dem = rio.open(input[0])
        st = gpd.read_file(input[1])

        st.crs = {'init': 'epsg:4326'}
        st_dem = st.to_crs(dem.crs)

        # Create a graph from the streets
        G = nx.Graph()
        for idx, row in st.iterrows():
            coords = row.geometry.coords
            start = np.round(coords[0], 6)
            end = np.round(coords[-1], 6)

            node_start = str(start)
            node_end = str(end)

            G.add_node(node_start, x=start[0], y=start[1])
            G.add_node(node_end, x=end[0], y=end[1])
            # Retain orientation information
            G.add_edge(node_start, node_end, start=node_start,
                       geometry=row.geometry,
                       geometry_dem=st_dem.loc[idx, 'geometry'])

        # Create the geometries for the mask - intersections extended a small
        # distance
        rows = []
        n = 0
        for node, degree in G.degree:
            if (degree == 1) or (degree > 2):
                n += 1
                # It's an intersection or a dead end
                for u, v, d in G.edges(node, data=True):
                    geom = d['geometry']
                    geom_dem = d['geometry_dem']
                    if u == d['start']:
                        x, y = geom.coords[0]
                        x_dem, y_dem = geom_dem.coords[0]
                    else:
                        x, y = geom.coords[-1]
                        x_dem, y_dem = geom_dem.coords[-1]
                    elevation = dh.raster_interp.interpolated_value(x_dem, y_dem, dem)
                    rows.append({
                        'geometry': Point(x, y),
                        'elevation': elevation
                    })

        gdf = gpd.GeoDataFrame(rows)
        dh.io.gdf_to_geojson(gdf, output[0])


rule add_inclines:
    input:
        ['interim/redrawn/sidewalks.geojson',
         'interim/dem/intersection_elevations.geojson']
    output:
        'interim/inclined/sidewalks.geojson'
    run:
        sw = gpd.read_file(input[0])
        el = gpd.read_file(input[1])

        sw = dh.utm.gdf_to_utm(sw)
        el = dh.utm.gdf_to_utm(el)

        el['x'] = el.geometry.apply(lambda p: p.x)
        el['y'] = el.geometry.apply(lambda p: p.y)

        convex_hull = LinearRing(MultiPoint(el.geometry).convex_hull.exterior.coords)

        interpolate = scipy.interpolate.LinearNDInterpolator(el[['x', 'y']],
                                                             el['elevation'],
                                                             fill_value=-1000)

        sw['ele_start'] = sw.geometry.apply(lambda l: interpolate(*l.coords[0]))
        sw['ele_end'] = sw.geometry.apply(lambda l: interpolate(*l.coords[-1]))
        sw['len'] = sw.geometry.length

        # If interpolated elevation is -1000, that means we just failed to
        # interpolate at all. We should 'snap' that point to the nearest valid
        # section of the interpolator, which is a convex hull of the
        # intersections.
        missed = sw.loc[(sw.ele_start == -1000) | (sw.ele_end == -1000)]
        for idx, row in missed.iterrows():
            factor = 1
            if row.ele_start == -1000:
                start = Point(row.geometry.coords[0])
                proj_start = convex_hull.interpolate(convex_hull.project(start))

                dx = (proj_start.x - start.x)
                dy = (proj_start.y - start.y)
                len = dx**2 + dy**2
                dx = factor * dx / len
                dy = factor * dy / len
                x = proj_start.x + dx
                y = proj_start.y + dy
                point_start = Point(x, y)
                sw.loc[idx, 'ele_start'] = interpolate(*point_start.coords)

            if row.ele_end == -1000:
                end = Point(row.geometry.coords[-1])
                proj_end = convex_hull.interpolate(convex_hull.project(end))
                dx = (proj_end.x - end.x)
                dy = (proj_end.y - end.y)
                len = dx**2 + dy**2
                dx = factor * dx / len
                dy = factor * dy / len
                x = proj_end.x + dx
                y = proj_end.y + dy
                point_end = Point(x, y)
                sw.loc[idx, 'ele_end'] = interpolate(*point_end.coords)

        # If there's still some missing, just snap to the closest
        missed = sw.loc[(sw.ele_start == -1000) | (sw.ele_end == -1000)]
        for idx, row in missed.iterrows():
            if row.ele_start == -1000:
                start = Point(row.geometry.coords[0])
                idx2 = el.distance(start).sort_values().index.iloc[0]
                sw.loc[idx, 'ele_start'] = el.loc[idx2, 'elevation']

            if row.ele_end == -1000:
                end = Point(row.geometry.coords[-1])
                idx2 = el.distance(end).sort_values().index.iloc[0]
                sw.loc[idx, 'ele_end'] = el.loc[idx2, 'elevation']

        sw['incline'] = (sw.ele_end - sw.ele_start) / sw.len
        sw = sw.drop(columns=['ele_start', 'ele_end', 'len'])

        sw.incline = round(sw.incline, 3)
        sw.incline = sw.incline.apply(lambda x: min(max(x, -1), 1))

        sw = sw.to_crs({'init': 'epsg:4326'})

        dh.io.gdf_to_geojson(sw, output[0])

        gdf2 = gpd.GeoDataFrame(geometry=[Polygon(convex_hull)])
        gdf2.crs = sw.crs
        gdf2 = gdf2.to_crs({'init': 'epsg:4326'})
        dh.io.gdf_to_geojson(gdf2, 'interim/inclined/hull.geojson')


rule snap_elevator_paths:
    input:
        ['interim/clean/elevator_paths.geojson',
         'interim/inclined/sidewalks.geojson']
    output:
        'interim/networked/elevator_paths.geojson'
    run:
        el = gpd.read_file(input[0])
        sw = gpd.read_file(input[1])

        # Find closest sidewalk
        for idx, row in el.iterrows():
            coords = list(row.geometry.coords)
            start = coords[0]
            end = coords[-1]
            point_start = Point(start)
            point_end = Point(end)

            r = 1e-5

            new = []
            for p in (point_start, point_end):
                bbox = [p.x - r, p.y - r, p.x + r, p.y + r]
                query = sw.sindex.intersection(bbox, objects=True)
                sw_bbox = sw.loc[[q.object for q in query]].geometry
                closest_dist = sw_bbox.distance(p).sort_values().index[0]
                closest = sw.loc[closest_dist]
                new_point = closest.geometry.interpolate(closest.geometry.project(p))
                new.append(tuple(new_point.coords[0]))

            coords[0] = new[0]
            coords[-1] = new[1]

            new_geometry = LineString(coords)
            el.loc[idx, 'geometry'] = new_geometry

        dh.io.gdf_to_geojson(el, output[0])


rule network:
    input:
        ['interim/inclined/sidewalks.geojson',
         'interim/annotated/crossings.geojson',
         'interim/networked/elevator_paths.geojson']
    output:
        'interim/networked/sidewalks.geojson'
    run:
        sw = gpd.read_file(input[0])
        cr = gpd.read_file(input[1])
        el = gpd.read_file(input[2])

        sw.crs = {'init': 'epsg:4326'}
        cr.crs = {'init': 'epsg:4326'}

        sw = dh.utm.gdf_to_utm(sw)
        cr = dh.utm.gdf_to_utm(cr)
        el = dh.utm.gdf_to_utm(el)

        sw_network = dh.ped_network.network_sidewalks(sw, [cr, el])

        # Set short sidewalk paths to 0 incline - they're likely at crossings
        # TODO: fancier / smarter version
        # Calculate new lengths
        sw_network['length'] = sw_network.geometry.length
        sw_network.loc[sw_network.length < 4, 'incline'] = 0

        sw_network.crs = sw.crs
        sw_network = sw_network.to_crs({'init': 'epsg:4326'})

        dh.io.gdf_to_geojson(sw_network, output[0])


rule cleanup:
    input:
        ['interim/annotated/crossings.geojson',
         'interim/networked/elevator_paths.geojson',
         'interim/networked/sidewalks.geojson']
    output:
        expand('interim/cleanup/{layer}.geojson', layer=['crossings', 'elevator_paths', 'sidewalks'])
    run:
        for in_path, out_path in zip(input, output):
            # Calculate length in UTM (TODO: just use Haversine? More accurate.)
            df = gpd.read_file(in_path)
            df.crs = {'init': 'epsg:4326'}
            df_utm = dh.utm.gdf_to_utm(df)
            df['length'] = df_utm.length.round(2)

            # Quantize coordinates - only need 8th decimal place tops
            def rounded_linestring(geometry, precision=8):
                return LineString(np.round(geometry.coords, precision))

            df["geometry"] = df.geometry.apply(rounded_linestring)

            # FIXME: Figure out why "forward" becomes a float in the first place
            # TODO: Add schema validation / type coercion? Serves as test + hand-wavy
            # automatic fixer
            if "sidewalks.geojson" in in_path:
                df["forward"] = df["forward"].astype(int)

            dh.io.gdf_to_geojson(df, out_path)


rule standardize:
    input:
        ['interim/cleanup/crossings.geojson',
         'interim/cleanup/sidewalks.geojson',
         'interim/cleanup/elevator_paths.geojson']
    output:
        "output/transportation.geojson"
    run:
        transportation = {
            "type": "FeatureCollection",
            "features": []
        }

        # Crossings - standardize to new schema
        with open(input[0]) as f:
            cr = json.load(f)

        for feature in cr["features"]:
            props = feature["properties"]
            new_props = {}
            new_props["subclass"] = "footway"
            new_props["footway"] = "crossing"
            if "marked" in props:
                if props["marked"]:
                    new_props["crossing"] = "marked"
                else:
                    new_props["crossing"] = "unmarked"
            if "curbramps" in props:
                new_props["curbramps"] = props["curbramps"]
            if "length" in props:
                new_props["length"] = props["length"]
            if "street_name" in props:
                new_props["description"] = "Crossing at {}".format(props["street_name"])

            transportation["features"].append({
                "type": "Feature",
                "geometry": feature["geometry"],
                "properties": new_props
            })

        # Sidewalks - standardize to new schema
        with open(input[1]) as f:
            sw = json.load(f)

        for feature in sw["features"]:
            props = feature["properties"]
            new_props = {}
            new_props["subclass"] = "footway"
            new_props["footway"] = "sidewalk"
            if "incline" in props:
                new_props["incline"] = props["incline"]
            if "surface" in props:
                new_props["surface"] = props["surface"]
            if "width" in props:
                new_props["width"] = props["width"]
            if "length" in props:
                new_props["length"] = props["length"]
            if "layer" in props:
                new_props["layer"] = props["layer"]
            if "side" in props and "street_name" in props:
                new_props["description"] = "Sidewalk {} of {}".format(props["side"], props["street_name"])

            transportation["features"].append({
                "type": "Feature",
                "geometry": feature["geometry"],
                "properties": new_props
            })

        # Elevator path(s) - standardize to new schema
        with open(input[2]) as f:
            el = json.load(f)
            props = feature["properties"]
            new_props = {}
            # TODO: retain original OpenStreetMap data tags - clarify corridors vs.
            # footways.
            new_props["subclass"] = "footway"
            new_props["elevator"] = 1
            if "indoor" in props:
                new_props["indoor"] = props["indoor"]
            if "layer" in props:
                new_props["layer"] = props["layer"]
            if "length" in props:
                new_props["length"] = props["length"]
            if "opening_hours" in props:
                new_props["opening_hours"] = props["opening_hours"]
            if "via" in props:
                new_props["description"] = "Elevator via {}".format(props["via"])

            transportation["features"].append({
                "type": "Feature",
                "geometry": feature["geometry"],
                "properties": new_props
            })

        with open(output[0], "w") as g:
            json.dump(transportation, g)
